{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from pathlib import Path\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(InMemoryDataset):\n",
    "    \"\"\"\n",
    "    PyG dataset for patient graphs (loads entire graph).\n",
    "    \"\"\"\n",
    "    def __init__(self, config, transform=None, pre_transform=None):\n",
    "        super(GraphDataset, self).__init__(root=config[\"data_dir\"], transform=transform, pre_transform=pre_transform)\n",
    "\n",
    "        # === 1. Load Entire Graph ===\n",
    "        graph_path = Path(config[\"graph_dir\"]) / f\"diagnosis_graph_{config['mode']}_k{config['k']}.pt\"\n",
    "        print(f\"==> Loading precomputed graph from {graph_path}\")\n",
    "        self.graph_data = torch.load(graph_path, weights_only=False)\n",
    "\n",
    "        # === 2. Extract edge_index and edge_attr ===\n",
    "        self.edge_index = self.graph_data.edge_index\n",
    "        self.edge_attr = self.graph_data.edge_attr\n",
    "\n",
    "        # === 3. Load Flat Features ===\n",
    "        flat_path = Path(config[\"data_dir\"]) / \"final_flat.h5\"\n",
    "        print(f\"==> Loading flat features from {flat_path}\")\n",
    "        flat_df = pd.read_hdf(flat_path).set_index(\"patient\")\n",
    "        flat_df.index = flat_df.index.astype(int)\n",
    "\n",
    "        # Align patient IDs with graph\n",
    "        self.graph_data.patient_ids = self.graph_data.patient_ids.clone().detach().long()\n",
    "        self.graph_data.x = torch.tensor(flat_df.loc[self.graph_data.patient_ids.numpy()].values, dtype=torch.float)\n",
    "        self.graph_data.num_nodes = self.graph_data.x.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_loader(graph_dataset, patient_ids, sizes, batch_size, shuffle):\n",
    "    \"\"\"\n",
    "    只采样 LSTM batch 的 `patient_ids`，防止 `NeighborSampler` 额外加入邻居节点\n",
    "    \"\"\"\n",
    "    # **获取 `patient_ids` 在 `graph_dataset` 中的索引**\n",
    "    graph_patient_ids = graph_dataset.graph_data.patient_ids\n",
    "    \n",
    "    # 只选择当前 batch `patient_ids` 在 Graph 数据中的索引\n",
    "    node_idx = torch.tensor([torch.where(graph_patient_ids == pid)[0][0] for pid in patient_ids if pid in graph_patient_ids], dtype=torch.long)\n",
    "    \n",
    "    # **创建 NeighborSampler**\n",
    "    loader = NeighborSampler(\n",
    "        edge_index=graph_dataset.graph_data.edge_index,\n",
    "        node_idx=node_idx,  # 仅采样 `patient_ids` 的图节点\n",
    "        sizes=sizes,\n",
    "        batch_size=batch_size,  # `batch_size` 必须等于 LSTM batch 大小\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {  \n",
    "    \"data_dir\": \"/home/mei/nas/docker/thesis/data/hdf\",\n",
    "    \"graph_dir\": \"/home/mei/nas/docker/thesis/data/graphs\",\n",
    "    \"mode\": \"k_closest\",\n",
    "    \"k\": 3\n",
    "          \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids=[4854, 7605, 7343, 4752, 4989, 1690, 1590, 1266, 1829, 5949, 7599, 962, 4316, 7313, 7685, 4486, 4769, 3295, 2614, 5275, 5470, 3914, 104, 6128, 5850, 3608, 2876, 330, 6051, 1228, 7874]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading precomputed graph from /home/mei/nas/docker/thesis/data/graphs/diagnosis_graph_k_closest_k3.pt\n",
      "==> Loading flat features from /home/mei/nas/docker/thesis/data/hdf/final_flat.h5\n"
     ]
    }
   ],
   "source": [
    "graph_dataset = GraphDataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborSampler\n",
    "\n",
    "graph_dataset = GraphDataset(config)\n",
    "\n",
    "sample_sizes = [10, 10]  # 每层采样邻居数量\n",
    "batch_size = 32\n",
    "\n",
    "input_nodes = torch.arange(0, graph_dataset.graph_data.num_nodes)  \n",
    "loader =  NeighborSampler(\n",
    "    graph_dataset.graph_data.edge_index,\n",
    "    node_idx=graph_dataset.graph_data.val_mask,\n",
    "    sizes=sample_sizes,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 遍历一个 batch\n",
    "for batch_size, n_id, adjs in loader:\n",
    "    print(\"Batch size:\", batch_size)\n",
    "    print(\"Node IDs:\", n_id)\n",
    "    \n",
    "    # 提取节点属性\n",
    "    node_features = graph_dataset.graph_data.x[n_id]\n",
    "    print(\"Node features shape:\", node_features.shape)\n",
    "    print(\"Node features:\", node_features)\n",
    "    \n",
    "    for edge_index, e_id, size in adjs:\n",
    "        print(\"Edge index shape:\", edge_index.shape)\n",
    "        print(\"Edge IDs:\", e_id)\n",
    "        print(\"Size:\", size)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(InMemoryDataset):\n",
    "    \"\"\"\n",
    "    PyG dataset for patient graphs aligned with MultiModalDataset patient IDs.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, multimodal_patient_ids, transform=None, pre_transform=None):\n",
    "        super(GraphDataset, self).__init__(root=config[\"data_dir\"], transform=transform, pre_transform=pre_transform)\n",
    "\n",
    "        # === 1. Load Graph ===\n",
    "        graph_path = Path(config[\"graph_dir\"]) / f\"diagnosis_graph_{config['mode']}_k{config['k']}.pt\"\n",
    "        print(f\"==> Loading precomputed graph from {graph_path}\")\n",
    "        self.graph_data = torch.load(graph_path, weights_only=False)\n",
    "\n",
    "        # === 2. Extract edge_index and edge_attr ===\n",
    "        self.edge_index = self.graph_data.edge_index\n",
    "        self.edge_attr = self.graph_data.edge_attr\n",
    "\n",
    "        # === 3. Align Graph Patient IDs with MultiModalDataset ===\n",
    "        if isinstance(self.graph_data.patient_ids, torch.Tensor):\n",
    "            graph_patient_ids = self.graph_data.patient_ids.numpy()\n",
    "        else:\n",
    "            graph_patient_ids = np.array(self.graph_data.patient_ids)\n",
    "\n",
    "        # 将 MultiModalDataset 中存在的 patient_ids 作为筛选条件\n",
    "        self.patient_ids = np.array([pid for pid in multimodal_patient_ids if pid in graph_patient_ids])\n",
    "\n",
    "        # 找到对应索引位置（用 numpy 加速）\n",
    "        patient_id_indices = np.where(np.isin(graph_patient_ids, self.patient_ids))[0]\n",
    "\n",
    "        # === 4. Load Flat Features and Align ===\n",
    "        flat_path = Path(config[\"data_dir\"]) / \"final_flat.h5\"\n",
    "        print(f\"==> Loading flat features from {flat_path}\")\n",
    "        flat_df = pd.read_hdf(flat_path).set_index(\"patient\")\n",
    "        flat_df.index = flat_df.index.astype(int)\n",
    "\n",
    "        # 对齐 flat 特征，确保 patient_ids 存在于 flat_df\n",
    "        flat_df_aligned = flat_df.loc[self.patient_ids]\n",
    "        x_flat = torch.tensor(flat_df_aligned.values, dtype=torch.float)\n",
    "        self.graph_data.x = x_flat\n",
    "        self.graph_data.num_nodes = len(self.patient_ids)\n",
    "\n",
    "        # === 5. 更新 edge_index 以反映新的节点索引映射 ===\n",
    "        old_to_new_idx = {old_idx: new_idx for new_idx, old_idx in enumerate(patient_id_indices)}\n",
    "\n",
    "        # 使用张量筛选有效边（两端节点都在 patient_id_indices 中）\n",
    "        src_nodes = self.edge_index[0].numpy()\n",
    "        dst_nodes = self.edge_index[1].numpy()\n",
    "\n",
    "        valid_src_mask = np.isin(src_nodes, patient_id_indices)\n",
    "        valid_dst_mask = np.isin(dst_nodes, patient_id_indices)\n",
    "        valid_edges_mask = valid_src_mask & valid_dst_mask\n",
    "\n",
    "        # 筛选有效的 edge_index 和 edge_attr\n",
    "        filtered_edge_index = self.edge_index[:, valid_edges_mask]\n",
    "        filtered_edge_attr = self.edge_attr[valid_edges_mask]\n",
    "\n",
    "        # 重映射边的索引\n",
    "        remapped_src = np.array([old_to_new_idx[src] for src in filtered_edge_index[0].numpy()])\n",
    "        remapped_dst = np.array([old_to_new_idx[dst] for dst in filtered_edge_index[1].numpy()])\n",
    "\n",
    "        remapped_edge_index = torch.tensor([remapped_src, remapped_dst], dtype=torch.long)\n",
    "\n",
    "        # 更新 graph_data\n",
    "        self.graph_data.edge_index = remapped_edge_index\n",
    "        self.graph_data.edge_attr = filtered_edge_attr\n",
    "        self.graph_data.patient_ids = torch.tensor(self.patient_ids, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graph_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_loader (graph_dataset,sizes,batch_size,shuffle):\n",
    "    \n",
    "    loader = NeighborSampler(\n",
    "        graph_dataset.graph_data.edge_index,\n",
    "        node_idx=torch.arange(graph_dataset.graph_data.num_nodes),\n",
    "        sizes=sizes,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborSampler\n",
    "\n",
    "graph_dataset = GraphDataset(config, multimodal_patient_ids=multi_modal_patient_ids)\n",
    "\n",
    "train_loader = NeighborSampler(\n",
    "    graph_dataset.graph_data.edge_index,\n",
    "    node_idx=torch.arange(graph_dataset.graph_data.num_nodes),  # 所有与 MultiModalDataset 对齐的节点\n",
    "    sizes=[10, 10],  # 采样邻居数量\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eicu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
