{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from pathlib import Path\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(InMemoryDataset):\n",
    "    \"\"\"\n",
    "    PyG dataset for patient graphs (loads entire graph).\n",
    "    \"\"\"\n",
    "    def __init__(self, config, transform=None, pre_transform=None):\n",
    "        super(GraphDataset, self).__init__(root=config[\"data_dir\"], transform=transform, pre_transform=pre_transform)\n",
    "\n",
    "        # === 1. Load Entire Graph ===\n",
    "        graph_path = Path(config[\"graph_dir\"]) / f\"diagnosis_graph_{config['mode']}_k{config['k']}.pt\"\n",
    "        print(f\"==> Loading precomputed graph from {graph_path}\")\n",
    "        self.graph_data = torch.load(graph_path, weights_only=False)\n",
    "\n",
    "        # === 2. Extract edge_index and edge_attr ===\n",
    "        self.edge_index = self.graph_data.edge_index\n",
    "        self.edge_attr = self.graph_data.edge_attr\n",
    "\n",
    "        # === 3. Load Flat Features ===\n",
    "        flat_path = Path(config[\"data_dir\"]) / \"final_flat.h5\"\n",
    "        print(f\"==> Loading flat features from {flat_path}\")\n",
    "        flat_df = pd.read_hdf(flat_path).set_index(\"patient\")\n",
    "        flat_df.index = flat_df.index.astype(int)\n",
    "\n",
    "        # Align patient IDs with graph\n",
    "        self.graph_data.patient_ids = self.graph_data.patient_ids.clone().detach().long()\n",
    "        self.graph_data.x = torch.tensor(flat_df.loc[self.graph_data.patient_ids.numpy()].values, dtype=torch.float)\n",
    "        self.graph_data.num_nodes = self.graph_data.x.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_loader(graph_dataset, patient_ids, sizes, batch_size, shuffle):\n",
    "    \"\"\"\n",
    "    只采样 LSTM batch 的 `patient_ids`，防止 `NeighborSampler` 额外加入邻居节点\n",
    "    \"\"\"\n",
    "    # **获取 `patient_ids` 在 `graph_dataset` 中的索引**\n",
    "    graph_patient_ids = graph_dataset.graph_data.patient_ids\n",
    "    \n",
    "    # 只选择当前 batch `patient_ids` 在 Graph 数据中的索引\n",
    "    node_idx = torch.tensor([torch.where(graph_patient_ids == pid)[0][0] for pid in patient_ids if pid in graph_patient_ids], dtype=torch.long)\n",
    "    \n",
    "    # **创建 NeighborSampler**\n",
    "    loader = NeighborSampler(\n",
    "        edge_index=graph_dataset.graph_data.edge_index,\n",
    "        node_idx=node_idx,  # 仅采样 `patient_ids` 的图节点\n",
    "        sizes=sizes,\n",
    "        batch_size=batch_size,  # `batch_size` 必须等于 LSTM batch 大小\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {  \n",
    "    \"data_dir\": \"/home/mei/nas/docker/thesis/data/hdf\",\n",
    "    \"graph_dir\": \"/home/mei/nas/docker/thesis/data/graphs\",\n",
    "    \"mode\": \"k_closest\",\n",
    "    \"k\": 3\n",
    "          \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids=[4854, 7605, 7343, 4752, 4989, 1690, 1590, 1266, 1829, 5949, 7599, 962, 4316, 7313, 7685, 4486, 4769, 3295, 2614, 5275, 5470, 3914, 104, 6128, 5850, 3608, 2876, 330, 6051, 1228, 7874]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading precomputed graph from /home/mei/nas/docker/thesis/data/graphs/diagnosis_graph_k_closest_k3.pt\n",
      "==> Loading flat features from /home/mei/nas/docker/thesis/data/hdf/final_flat.h5\n"
     ]
    }
   ],
   "source": [
    "graph_dataset = GraphDataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ The graph is Connected.\n",
      "🔹 Number of connected components: 1\n",
      "🔹 Largest component size: 11698\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "# **将 PyG 图转换为 NetworkX 图**\n",
    "graph_nx = to_networkx(graph_dataset.graph_data, to_undirected=True)\n",
    "\n",
    "# **检查是否是连通图**\n",
    "is_connected = nx.is_connected(graph_nx)\n",
    "print(f\"✅ The graph is {'Connected' if is_connected else 'NOT Connected'}.\")\n",
    "\n",
    "# **如果图不是连通的，检查连通分量**\n",
    "connected_components = list(nx.connected_components(graph_nx))\n",
    "print(f\"🔹 Number of connected components: {len(connected_components)}\")\n",
    "\n",
    "# **打印最大连通分量**\n",
    "largest_cc = max(connected_components, key=len)\n",
    "print(f\"🔹 Largest component size: {len(largest_cc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m patient_ids_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mint\u001b[39m(pid) \u001b[38;5;28;01mfor\u001b[39;00m pid \u001b[38;5;129;01min\u001b[39;00m patient_ids], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m----> 3\u001b[0m graph_batch \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatient_ids_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 传入 LSTM batch 里的 patient_ids\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpatient_ids_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# **确保 batch_size 与 LSTM 一致**\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m batch_size, n_id, adjs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(graph_batch))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampled node ids: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_id\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m, in \u001b[0;36mgraph_loader\u001b[0;34m(graph_dataset, patient_ids, sizes, batch_size, shuffle)\u001b[0m\n\u001b[1;32m      9\u001b[0m node_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([torch\u001b[38;5;241m.\u001b[39mwhere(graph_patient_ids \u001b[38;5;241m==\u001b[39m pid)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m pid \u001b[38;5;129;01min\u001b[39;00m patient_ids \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;129;01min\u001b[39;00m graph_patient_ids], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# **创建 NeighborSampler**\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mNeighborSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 仅采样 `patient_ids` 的图节点\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# `batch_size` 必须等于 LSTM batch 大小\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loader\n",
      "File \u001b[0;32m~/anaconda3/envs/eicu/lib/python3.10/site-packages/torch_geometric/loader/neighbor_sampler.py:142\u001b[0m, in \u001b[0;36mNeighborSampler.__init__\u001b[0;34m(self, edge_index, sizes, node_idx, num_nodes, return_e_id, transform, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     num_nodes \u001b[38;5;241m=\u001b[39m node_idx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (num_nodes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m node_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m node_idx\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong):\n\u001b[0;32m--> 142\u001b[0m     num_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(edge_index\u001b[38;5;241m.\u001b[39mmax()), \u001b[38;5;28mint\u001b[39m(\u001b[43mnode_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_nodes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     num_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(edge_index\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument."
     ]
    }
   ],
   "source": [
    "patient_ids_tensor = torch.tensor([int(pid) for pid in patient_ids], dtype=torch.long)\n",
    "\n",
    "graph_batch = graph_loader(\n",
    "    graph_dataset, \n",
    "    patient_ids_tensor,  # 传入 LSTM batch 里的 patient_ids\n",
    "    sizes=[10, 10], \n",
    "    batch_size=len(patient_ids_tensor),  # **确保 batch_size 与 LSTM 一致**\n",
    "    shuffle=True\n",
    "\n",
    ")\n",
    "batch_size, n_id, adjs = next(iter(graph_batch))\n",
    "print(f\"sampled node ids: {n_id.tolist()}\")\n",
    "print(f\"Edge index shape: {adjs[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborSampler\n",
    "\n",
    "graph_dataset = GraphDataset(config)\n",
    "\n",
    "sample_sizes = [10, 10]  # 每层采样邻居数量\n",
    "batch_size = 32\n",
    "\n",
    "input_nodes = torch.arange(0, graph_dataset.graph_data.num_nodes)  \n",
    "loader =  NeighborSampler(\n",
    "    graph_dataset.graph_data.edge_index,\n",
    "    node_idx=graph_dataset.graph_data.val_mask,\n",
    "    sizes=sample_sizes,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 遍历一个 batch\n",
    "for batch_size, n_id, adjs in loader:\n",
    "    print(\"Batch size:\", batch_size)\n",
    "    print(\"Node IDs:\", n_id)\n",
    "    \n",
    "    # 提取节点属性\n",
    "    node_features = graph_dataset.graph_data.x[n_id]\n",
    "    print(\"Node features shape:\", node_features.shape)\n",
    "    print(\"Node features:\", node_features)\n",
    "    \n",
    "    for edge_index, e_id, size in adjs:\n",
    "        print(\"Edge index shape:\", edge_index.shape)\n",
    "        print(\"Edge IDs:\", e_id)\n",
    "        print(\"Size:\", size)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(InMemoryDataset):\n",
    "    \"\"\"\n",
    "    PyG dataset for patient graphs aligned with MultiModalDataset patient IDs.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, multimodal_patient_ids, transform=None, pre_transform=None):\n",
    "        super(GraphDataset, self).__init__(root=config[\"data_dir\"], transform=transform, pre_transform=pre_transform)\n",
    "\n",
    "        # === 1. Load Graph ===\n",
    "        graph_path = Path(config[\"graph_dir\"]) / f\"diagnosis_graph_{config['mode']}_k{config['k']}.pt\"\n",
    "        print(f\"==> Loading precomputed graph from {graph_path}\")\n",
    "        self.graph_data = torch.load(graph_path, weights_only=False)\n",
    "\n",
    "        # === 2. Extract edge_index and edge_attr ===\n",
    "        self.edge_index = self.graph_data.edge_index\n",
    "        self.edge_attr = self.graph_data.edge_attr\n",
    "\n",
    "        # === 3. Align Graph Patient IDs with MultiModalDataset ===\n",
    "        if isinstance(self.graph_data.patient_ids, torch.Tensor):\n",
    "            graph_patient_ids = self.graph_data.patient_ids.numpy()\n",
    "        else:\n",
    "            graph_patient_ids = np.array(self.graph_data.patient_ids)\n",
    "\n",
    "        # 将 MultiModalDataset 中存在的 patient_ids 作为筛选条件\n",
    "        self.patient_ids = np.array([pid for pid in multimodal_patient_ids if pid in graph_patient_ids])\n",
    "\n",
    "        # 找到对应索引位置（用 numpy 加速）\n",
    "        patient_id_indices = np.where(np.isin(graph_patient_ids, self.patient_ids))[0]\n",
    "\n",
    "        # === 4. Load Flat Features and Align ===\n",
    "        flat_path = Path(config[\"data_dir\"]) / \"final_flat.h5\"\n",
    "        print(f\"==> Loading flat features from {flat_path}\")\n",
    "        flat_df = pd.read_hdf(flat_path).set_index(\"patient\")\n",
    "        flat_df.index = flat_df.index.astype(int)\n",
    "\n",
    "        # 对齐 flat 特征，确保 patient_ids 存在于 flat_df\n",
    "        flat_df_aligned = flat_df.loc[self.patient_ids]\n",
    "        x_flat = torch.tensor(flat_df_aligned.values, dtype=torch.float)\n",
    "        self.graph_data.x = x_flat\n",
    "        self.graph_data.num_nodes = len(self.patient_ids)\n",
    "\n",
    "        # === 5. 更新 edge_index 以反映新的节点索引映射 ===\n",
    "        old_to_new_idx = {old_idx: new_idx for new_idx, old_idx in enumerate(patient_id_indices)}\n",
    "\n",
    "        # 使用张量筛选有效边（两端节点都在 patient_id_indices 中）\n",
    "        src_nodes = self.edge_index[0].numpy()\n",
    "        dst_nodes = self.edge_index[1].numpy()\n",
    "\n",
    "        valid_src_mask = np.isin(src_nodes, patient_id_indices)\n",
    "        valid_dst_mask = np.isin(dst_nodes, patient_id_indices)\n",
    "        valid_edges_mask = valid_src_mask & valid_dst_mask\n",
    "\n",
    "        # 筛选有效的 edge_index 和 edge_attr\n",
    "        filtered_edge_index = self.edge_index[:, valid_edges_mask]\n",
    "        filtered_edge_attr = self.edge_attr[valid_edges_mask]\n",
    "\n",
    "        # 重映射边的索引\n",
    "        remapped_src = np.array([old_to_new_idx[src] for src in filtered_edge_index[0].numpy()])\n",
    "        remapped_dst = np.array([old_to_new_idx[dst] for dst in filtered_edge_index[1].numpy()])\n",
    "\n",
    "        remapped_edge_index = torch.tensor([remapped_src, remapped_dst], dtype=torch.long)\n",
    "\n",
    "        # 更新 graph_data\n",
    "        self.graph_data.edge_index = remapped_edge_index\n",
    "        self.graph_data.edge_attr = filtered_edge_attr\n",
    "        self.graph_data.patient_ids = torch.tensor(self.patient_ids, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graph_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_loader (graph_dataset,sizes,batch_size,shuffle):\n",
    "    \n",
    "    loader = NeighborSampler(\n",
    "        graph_dataset.graph_data.edge_index,\n",
    "        node_idx=torch.arange(graph_dataset.graph_data.num_nodes),\n",
    "        sizes=sizes,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborSampler\n",
    "\n",
    "graph_dataset = GraphDataset(config, multimodal_patient_ids=multi_modal_patient_ids)\n",
    "\n",
    "train_loader = NeighborSampler(\n",
    "    graph_dataset.graph_data.edge_index,\n",
    "    node_idx=torch.arange(graph_dataset.graph_data.num_nodes),  # 所有与 MultiModalDataset 对齐的节点\n",
    "    sizes=[10, 10],  # 采样邻居数量\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eicu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
