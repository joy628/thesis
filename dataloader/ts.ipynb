{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataloaders for lstm_only model\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.ts_h5_file = os.path.join(self.data_path, 'ts_each_patient_np.h5')\n",
    "        self.risks_h5_file = os.path.join(self.data_path, 'risk_scores_each_patient_np.h5')\n",
    "        self.flat_h5_file = os.path.join(self.data_path, 'flat.h5')\n",
    "        \n",
    "        self.ts_h5f = h5py.File(self.ts_h5_file, 'r')\n",
    "        self.risk_h5f = h5py.File(self.risks_h5_file, 'r')\n",
    "        self.flat_data = pd.read_hdf(self.flat_h5_file)\n",
    "        \n",
    "        self.patient_ids = list(self.ts_h5f.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_id = self.patient_ids[idx]\n",
    "        \n",
    "        ts_data = self.ts_h5f[patient_id][:, 1:] \n",
    "        risk_data = self.risk_h5f[patient_id][:]\n",
    "        flat_data = self.flat_data.loc[int(patient_id)].values\n",
    "        \n",
    "        ts_data = torch.tensor(ts_data, dtype=torch.float32)\n",
    "        flat_data = torch.tensor(flat_data, dtype=torch.float32)\n",
    "        risk_data = torch.tensor(risk_data, dtype=torch.float32)\n",
    "        \n",
    "        return patient_id, ts_data, flat_data, risk_data\n",
    "\n",
    "    def close(self):\n",
    "        self.ts_h5f.close()\n",
    "        self.risk_h5f.close()\n",
    "\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    patient_ids, ts_list, flat_list, risk_list = zip(*batch)\n",
    "    lengths = [x.shape[0] for x in ts_list]\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "\n",
    "    # order by length\n",
    "    lengths, sorted_idx = torch.sort(lengths, descending=True)\n",
    "    ts_list = [ts_list[i] for i in sorted_idx]\n",
    "    risk_list = [risk_list[i] for i in sorted_idx]\n",
    "    flat_list = [flat_list[i] for i in sorted_idx]\n",
    "    patient_ids = [patient_ids[i] for i in sorted_idx]\n",
    "\n",
    "    # pad sequences\n",
    "    padding_value = -99\n",
    "    padded_ts = pad_sequence(ts_list, batch_first=True, padding_value=padding_value)\n",
    "    padded_risk = pad_sequence(risk_list, batch_first=True, padding_value=padding_value)\n",
    "    flat_data = torch.stack(flat_list)\n",
    "\n",
    "    return patient_ids, padded_ts, flat_data, padded_risk, lengths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/home/mei/nas/docker/thesis/data/hdf/train\"\n",
    "dataset = MultiModalDataset(data_path)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient IDs: ['3132351', '1788546']\n",
      "Packed Time Series Data Shape: torch.Size([2, 1759, 162])\n",
      "Flat Data Shape: torch.Size([2, 104])\n",
      "Risks Data Shape: torch.Size([2, 1759])\n",
      "Lengths: tensor([1759,  422])\n"
     ]
    }
   ],
   "source": [
    "for patient_ids, packed_ts_data, flat_data, risks_data,lengths in dataloader:\n",
    "    print(\"Patient IDs:\", patient_ids)\n",
    "    print(\"Packed Time Series Data Shape:\", packed_ts_data.shape)\n",
    "    print(\"Flat Data Shape:\", flat_data.shape)\n",
    "    print(\"Risks Data Shape:\", risks_data.shape)\n",
    "    print(\"Lengths:\", lengths)\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_h5_file = os.path.join(data_path, 'ts_each_patient_np.h5')\n",
    "with h5py.File(ts_h5_file, 'r') as f:\n",
    "    ts_data = {key: np.array(f[key]) for key in f.keys()}\n",
    "\n",
    "risks_h5_file = os.path.join(data_path, 'risk_scores_each_patient_np.h5')\n",
    "with h5py.File(risks_h5_file, 'r') as f:\n",
    "    risk_data = {key: np.array(f[key]) for key in f.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series length for patient 1788546: 422\n",
      "Risk series length for patient 1788546: 422\n"
     ]
    }
   ],
   "source": [
    "\n",
    "patient_id = '1788546' \n",
    "if patient_id in ts_data:\n",
    "    ts_series = ts_data[patient_id]\n",
    "    print(f\"Time series length for patient {patient_id}: {len(ts_series)}\")\n",
    "    \n",
    "if patient_id in risk_data:\n",
    "    risk_series = risk_data[patient_id]\n",
    "    print(f\"Risk series length for patient {patient_id}: {len(risk_series)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eicu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
