{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"../paths.json\", \"r\") as f:\n",
    "        paths = json.load(f)\n",
    "        csv = paths['eICU_path'] \n",
    "        graph = paths['graph_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of all diagnoses is:  (10023, 115)\n"
     ]
    }
   ],
   "source": [
    "train_diagnoses = pd.read_csv(f'{csv}/train/diagnoses.csv', index_col='patient')\n",
    "val_diagnoses = pd.read_csv(f'{csv}/val/diagnoses.csv', index_col='patient')\n",
    "test_diagnoses = pd.read_csv(f'{csv}/test/diagnoses.csv', index_col='patient')\n",
    "all_diagnoses = pd.concat([train_diagnoses, val_diagnoses, test_diagnoses], axis=0)\n",
    "\n",
    "print(\"the size of all diagnoses is: \", all_diagnoses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"k\": 3,  # 'Number of nearest neighbors for k_closest mode\n",
    "    \"mode\": 'k_closest',  # Graph mode: k_closest or threshold\n",
    "    \"freq_adjust\": 'store_true',  # Apply frequency adjustment\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_adjustment = all_diagnoses.sum(axis=0) if args[\"freq_adjust\"] else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Get the best device (CUDA or CPU) for computation.\"\"\"\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def calculate_score_matrix(diagnoses, freq_adjustment=None, debug=False):\n",
    "    \"\"\"Calculate the score matrix based on diagnosis data.\"\"\"\n",
    "    print('==> Calculating score matrix')\n",
    "    device = get_device()\n",
    "    \n",
    "    # Convert diagnoses to a PyTorch tensor\n",
    "    diagnoses = torch.tensor(diagnoses.values, dtype=torch.float16, device=device)\n",
    "    \n",
    "    if freq_adjustment is not None:\n",
    "        freq_adjustment = torch.tensor(freq_adjustment.values, dtype=torch.float16, device=device)\n",
    "        freq_adjustment = 1 / (freq_adjustment + 1e-8)  # Avoid division by zero\n",
    "        freq_adjustment = freq_adjustment.unsqueeze(0)  # Make it broadcastable\n",
    "        diagnoses *= freq_adjustment  # Apply frequency adjustment\n",
    "    \n",
    "    if debug:\n",
    "        diagnoses = diagnoses[:1000]  # Limit data size in debug mode\n",
    "\n",
    "    num_rows = diagnoses.size(0)\n",
    "    scores = torch.zeros((num_rows, num_rows), dtype=torch.float16, device=device)\n",
    "    batch_size = 500\n",
    "    \n",
    "    print(f'==> Processing in batches (batch size: {batch_size})...')\n",
    "\n",
    "    # Compute score matrix in batches\n",
    "    for start in range(0, num_rows, batch_size):\n",
    "        end = min(start + batch_size, num_rows)\n",
    "        batch = diagnoses[start:end]\n",
    "        scores[start:end] = torch.mm(batch, diagnoses.T)\n",
    "\n",
    "        # Clear cache to reduce memory pressure\n",
    "        del batch\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Convert to CPU numpy array\n",
    "    scores = scores.cpu().numpy()\n",
    "    \n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Calculating score matrix\n",
      "==> Processing in batches (batch size: 500)...\n",
      "Score matrix shape: (10023, 10023)\n"
     ]
    }
   ],
   "source": [
    "# Calculate score matrix\n",
    "scores = calculate_score_matrix(all_diagnoses, freq_adjustment=freq_adjustment)\n",
    "print(f'Score matrix shape: {scores.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def create_graph_pyg(diagnoses, scores, k=3, penalize=True):\n",
    "    \"\"\"\n",
    "    use the score matrix to create a graph in PyG format\n",
    "    \"\"\"\n",
    "    print('==> Step 1: calculate the  Penalty Similarity ')\n",
    "    diagnoses = torch.tensor(diagnoses.values).float()\n",
    "    scores = torch.tensor(scores).float()\n",
    "    scores.fill_diagonal_(0)  # 去掉自连接\n",
    "\n",
    "    if penalize:\n",
    "        diags_per_pt = diagnoses.sum(axis=1)\n",
    "        total_combined_diags = diags_per_pt.view(-1, 1) + diags_per_pt.view(1, -1)\n",
    "        scores = 5 * scores - total_combined_diags  # 惩罚项\n",
    "\n",
    "    print('==> Step 2: select the top k edges')\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "\n",
    "    for i in range(scores.shape[0]):\n",
    "        k_highest = torch.topk(scores[i], k=k).indices\n",
    "        for j in k_highest:\n",
    "            edge_index.append([i, j.item()])\n",
    "            edge_attr.append(scores[i, j].item())  # 边的权重\n",
    "\n",
    "    edge_index = torch.tensor(edge_index).T  # 转换为 PyG 格式\n",
    "    edge_attr = torch.tensor(edge_attr).float()\n",
    "\n",
    "    print(f'==> generated {len(edge_attr)} edges')\n",
    "\n",
    "    print('==> Step 3: generate the PyG data object')\n",
    "    data = Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=len(diagnoses))\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Step 1: calculate the  Penalty Similarity \n",
      "==> Step 2: select the top k edges\n",
      "==> generated 30069 edges\n",
      "==> Step 3: generate the PyG data object\n"
     ]
    }
   ],
   "source": [
    "data = create_graph_pyg(all_diagnoses, scores, k=args[\"k\"], penalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the graph\n",
    "graph_path = f'{graph}/diagnosis_graph_{args[\"mode\"]}_k{args[\"k\"]}.pt'\n",
    "torch.save(data, graph_path)\n",
    "\n",
    "#locad the graph\n",
    "# loaded_data = torch.load(\"graph_data.pt\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "edges_df = pd.DataFrame({\"source\": data.edge_index[0].cpu().numpy(), \n",
    "                         \"target\": data.edge_index[1].cpu().numpy(), \n",
    "                         \"weight\": data.edge_attr.cpu().numpy()})\n",
    "\n",
    "# save the graph\n",
    "edges_df.to_csv(graph+\"graph_edges.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edges_df = pd.read_csv(graph+\"graph_edges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2625</td>\n",
       "      <td>-4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1628</td>\n",
       "      <td>-4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1643</td>\n",
       "      <td>-4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7279</td>\n",
       "      <td>-2.999988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1643</td>\n",
       "      <td>-3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30064</th>\n",
       "      <td>10021</td>\n",
       "      <td>1643</td>\n",
       "      <td>-3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30065</th>\n",
       "      <td>10021</td>\n",
       "      <td>1628</td>\n",
       "      <td>-3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30066</th>\n",
       "      <td>10022</td>\n",
       "      <td>4982</td>\n",
       "      <td>-4.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30067</th>\n",
       "      <td>10022</td>\n",
       "      <td>4705</td>\n",
       "      <td>-4.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30068</th>\n",
       "      <td>10022</td>\n",
       "      <td>1628</td>\n",
       "      <td>-4.999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30069 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source  target    weight\n",
       "0           0    2625 -4.000000\n",
       "1           0    1628 -4.000000\n",
       "2           0    1643 -4.000000\n",
       "3           1    7279 -2.999988\n",
       "4           1    1643 -3.000000\n",
       "...       ...     ...       ...\n",
       "30064   10021    1643 -3.000000\n",
       "30065   10021    1628 -3.000000\n",
       "30066   10022    4982 -4.999999\n",
       "30067   10022    4705 -4.999999\n",
       "30068   10022    1628 -4.999999\n",
       "\n",
       "[30069 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eicu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
