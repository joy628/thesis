{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.append('/home/mei/nas/docker/thesis')\n",
    "from model.lstm_gnn_embedding import PatientOutcomeModelEmbedding\n",
    "from dataloader.ts_reader import MultiModalDataset, collate_fn\n",
    "from dataloader.pyg_reader import GraphDataset\n",
    "from captum.attr import IntegratedGradients\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"/home/mei/nas/docker/thesis/data/hdf/train\"\n",
    "val_data_dir = \"/home/mei/nas/docker/thesis/data/hdf/val\"\n",
    "test_data_dir = \"/home/mei/nas/docker/thesis/data/hdf/test\"\n",
    "\n",
    "config = {  \n",
    "    \"data_dir\": \"/home/mei/nas/docker/thesis/data/hdf\",\n",
    "    \"graph_dir\": \"/home/mei/nas/docker/thesis/data/graphs\",\n",
    "    \"mode\": \"k_closest\",\n",
    "    \"k\": 3         \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading precomputed graph from /home/mei/nas/docker/thesis/data/graphs/diagnosis_graph_k_closest_k3.pt\n",
      "==> Loading flat features from /home/mei/nas/docker/thesis/data/hdf/final_flat.h5\n"
     ]
    }
   ],
   "source": [
    "# === LSTM + Flat Dataset ===\n",
    "lstm_dataset_train = MultiModalDataset(train_data_dir)\n",
    "lstm_dataset_val = MultiModalDataset(val_data_dir)\n",
    "lstm_dataset_test = MultiModalDataset(test_data_dir)\n",
    "\n",
    "lstm_loader_train = DataLoader(lstm_dataset_train , batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "lstm_loader_val = DataLoader(lstm_dataset_val , batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "lstm_loader_test = DataLoader(lstm_dataset_test , batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# === Graph Dataset ===\n",
    "\n",
    "graph_dataset = GraphDataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data= pd.read_hdf(test_data_dir+'/flat.h5')\n",
    "ts_data= pd.read_hdf(test_data_dir+'/timeseries.h5')\n",
    "feature_flat = list(flat_data.columns)\n",
    "feature_ts = list(ts_data.columns)\n",
    "feature_ts = feature_ts[1:] # remove 'time' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_input_dim = 104\n",
    "graph_input_dim = 104\n",
    "ts_input_dim = 162\n",
    "hidden_dim = 128\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   \n",
    "model = PatientOutcomeModelEmbedding(flat_input_dim, graph_input_dim, ts_input_dim, hidden_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dataset.graph_data.x = graph_dataset.graph_data.x.to(device)\n",
    "graph_dataset.graph_data.edge_index = graph_dataset.graph_data.edge_index.to(device)\n",
    "graph_dataset.graph_data.patient_ids =graph_dataset.graph_data.patient_ids.clone().detach().to(device)\n",
    "\n",
    "for patient_ids, ts_data, flat_data, risk_data, lengths in lstm_loader_val:\n",
    "    fixed_patient_ids = torch.tensor([int(pid) for pid in patient_ids], dtype=torch.long).to(device)  # shape: (N,)\n",
    "    fixed_ts = ts_data.to(device)  # shape: (N, T, D_ts)\n",
    "    fixed_lengths = lengths.to(device)  # shape: (N,)\n",
    "    fixed_flat = flat_data.to(device)  # shape: (N, D_flat)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapperForIG(nn.Module):\n",
    "    def __init__(self, model, graph_data, patient_ids_fixed, ts_data_fixed, lengths_fixed):\n",
    "        super(ModelWrapperForIG, self).__init__()\n",
    "        self.model = model\n",
    "        self.graph_data = graph_data\n",
    "        self.patient_ids_fixed = patient_ids_fixed  \n",
    "        self.ts_data_fixed = ts_data_fixed  \n",
    "        self.lengths_fixed = lengths_fixed  \n",
    "        \n",
    "    def forward(self, flat_input, ts_input):\n",
    "        \"\"\"\n",
    "        flat_input: tensor, shape (N, D_flat)\n",
    "        ts_input: tensor, shape (N, T, D_ts)\n",
    "        其他输入固定：graph_data, patient_ids_fixed, ts_data_fixed, lengths_fixed\n",
    "        这里我们将调用模型并返回每个样本 risk score 取所有时间步均\n",
    "        \"\"\"\n",
    "        risk_scores, _ = self.model(flat_input, self.graph_data, self.patient_ids_fixed, ts_input, self.lengths_fixed)\n",
    "        # risk_scores shape: (N, T) -> 返回每个样本在时间维度上的均值\n",
    "        return risk_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelWrapperForIG(\n",
       "  (model): PatientOutcomeModelEmbedding(\n",
       "    (flat_encoder): Linear(in_features=104, out_features=128, bias=True)\n",
       "    (graph_encoder): GraphEncoder(\n",
       "      (gcn1): GCNConv(104, 128)\n",
       "      (gcn2): GCNConv(128, 128)\n",
       "      (bn1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (ts_encoder): TimeSeriesEncoder(\n",
       "      (lstm): LSTM(162, 128, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "    (risk_predictor): RiskPredictor(\n",
       "      (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper = ModelWrapperForIG(model, graph_dataset.graph_data, fixed_patient_ids, fixed_ts, fixed_lengths)\n",
    "wrapper.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_flat(flat_input):\n",
    "    \"\"\"\n",
    "    解释平面特征：\n",
    "    flat_input: tensor, shape (N, D_flat)\n",
    "    固定 ts_input 使用 ts_sample（从测试集中选取的样本的时序部分）\n",
    "    \"\"\"\n",
    "    # 在这里，我们固定 ts_input 为测试样本 ts_sample（稍后获取）\n",
    "    risk_scores = wrapper(flat_input, ts_sample)\n",
    "    return risk_scores\n",
    "\n",
    "def forward_ts(ts_input):\n",
    "    \"\"\"\n",
    "    解释时序特征：\n",
    "    ts_input: tensor, shape (N, T, D_ts)\n",
    "    固定平面输入为 flat_sample（从测试集中选取的样本的平面部分）\n",
    "    \"\"\"\n",
    "    risk_scores = wrapper(flat_sample, ts_input)\n",
    "    return risk_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_sample shape: torch.Size([32, 3995, 162])\n",
      "baseline_ts shape: torch.Size([32, 3995, 162])\n"
     ]
    }
   ],
   "source": [
    "print(\"ts_sample shape:\", ts_sample.shape)\n",
    "print(\"baseline_ts shape:\", baseline_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient_ids, ts_data, flat_data, risk_data, lengths in lstm_loader_test:\n",
    "    flat_sample = flat_data.to(device)       # shape: (batch_size, D_flat)\n",
    "    ts_sample = ts_data.to(device)           # shape: (batch_size, T, D_ts)\n",
    "    # 为 Integrated Gradients 选择基线，通常使用全零\n",
    "    baseline_flat = torch.zeros_like(flat_sample)\n",
    "    baseline_ts = torch.zeros_like(ts_sample)\n",
    "    break\n",
    "\n",
    "\n",
    "ig_flat = IntegratedGradients(forward_flat)\n",
    "\n",
    "# 对于平面特征 Integrated Gradients，不设置 target 参数\n",
    "ig_flat = IntegratedGradients(forward_flat)\n",
    "attr_flat, delta_flat = ig_flat.attribute(flat_sample, baseline_flat, return_convergence_delta=True)\n",
    "print(\"Flat attribution:\", attr_flat)\n",
    "print(\"Flat convergence delta:\", delta_flat)\n",
    "\n",
    "# 对于时序特征 Integrated Gradients，也不设置 target 参数\n",
    "ig_ts = IntegratedGradients(forward_ts)\n",
    "attr_ts, delta_ts = ig_ts.attribute(ts_sample, baseline_ts, return_convergence_delta=True)\n",
    "print(\"Time series attribution:\", attr_ts)\n",
    "print(\"Time series convergence delta:\", delta_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_flat_np = attr_flat.mean(dim=0).cpu().detach().numpy()  # (D_flat,)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(attr_flat_np)), attr_flat_np)\n",
    "plt.xlabel(\"Flat Feature Index\")\n",
    "plt.ylabel(\"Attribution\")\n",
    "plt.title(\"Integrated Gradients for Flat Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_ts_np = attr_ts.mean(dim=0).cpu().detach().numpy()  # (T, D_ts)\n",
    "# 例如，我们取每个时间步所有特征的均值\n",
    "time_step_attr = attr_ts_np.mean(axis=1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(time_step_attr, marker='o')\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Mean Attribution\")\n",
    "plt.title(\"Integrated Gradients for Time Series Features (Averaged over Features)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapperForIG(torch.nn.Module):\n",
    "    def __init__(self, model, graph_data, patient_ids_fixed, ts_data_fixed, lengths_fixed):\n",
    "        \"\"\"\n",
    "        model: OutcomeModelEmbedding model, set it to eval mode\n",
    "        graph_data: fixed graph data\n",
    "        patient_ids_fixed: shape (N,)\n",
    "        ts_data_fixed: shape (N, T, D_ts)\n",
    "        lengths_fixed: the valid lengths of each time series in ts_data_fixed\n",
    "        \"\"\"\n",
    "        super(ModelWrapperForIG, self).__init__()\n",
    "        self.model = model\n",
    "        self.graph_data = graph_data\n",
    "        self.patient_ids_fixed = torch.tensor(patient_ids_fixed, dtype=torch.long).to(model.device)  # Ensure it's a tensor and on the same device\n",
    "        self.ts_data_fixed = ts_data_fixed.to(model.device)\n",
    "        self.lengths_fixed = lengths_fixed.to(model.device)\n",
    "        self.device = self.patient_ids_fixed.device  # Get the device\n",
    "\n",
    "    def forward(self, flat_input, ts_input):\n",
    "        \"\"\"\n",
    "        flat_input: tensor, shape (N, D_flat)\n",
    "        ts_input: tensor, shape (N, T, D_ts)\n",
    "        this function should return the risk scores for each sample in the batch\n",
    "        \"\"\"\n",
    "        # get risk_scores and combined embeddings\n",
    "        risk_scores, combined = self.model(flat_input, self.graph_data, self.patient_ids_fixed, ts_input, self.lengths_fixed)\n",
    "        # risk_scores shape is (N, T)\n",
    "        risk_mean = risk_scores.mean(dim=1)  # shape (N,)\n",
    "        return risk_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient_ids, ts_data, flat_data, risk_data ,lengths in lstm_loader_val:\n",
    "    patient_ids_fixed = patient_ids  # Ensure it's a list\n",
    "    ts_data_fixed = ts_data\n",
    "    lengths_fixed = lengths\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ts_data_fixed = ts_data_fixed.to(device)\n",
    "lengths_fixed = lengths_fixed.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wrapper \u001b[38;5;241m=\u001b[39m \u001b[43mModelWrapperForIG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatient_ids_fixed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts_data_fixed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths_fixed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m wrapper\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      4\u001b[0m ig \u001b[38;5;241m=\u001b[39m IntegratedGradients(wrapper)\n",
      "Cell \u001b[0;32mIn[25], line 13\u001b[0m, in \u001b[0;36mModelWrapperForIG.__init__\u001b[0;34m(self, model, graph_data, patient_ids_fixed, ts_data_fixed, lengths_fixed)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_data \u001b[38;5;241m=\u001b[39m graph_data\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatient_ids_fixed \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatient_ids_fixed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# Ensure it's a tensor and on the same device\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mts_data_fixed \u001b[38;5;241m=\u001b[39m ts_data_fixed\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlengths_fixed \u001b[38;5;241m=\u001b[39m lengths_fixed\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "wrapper = ModelWrapperForIG(model, graph_dataset.graph_data, patient_ids_fixed, ts_data_fixed, lengths_fixed)\n",
    "wrapper.eval()\n",
    "\n",
    "ig = IntegratedGradients(wrapper)\n",
    "\n",
    "# 选择一个输入样本和基线数据进行解释\n",
    "for patient_ids, ts_data, flat_data, risk_data in lstm_loader_test:\n",
    "    flat_input = flat_data.to(device)\n",
    "    ts_sample = ts_data.to(device)\n",
    "    baseline_ts = torch.zeros_like(ts_sample).to(device)  # 使用全零作为基线数据\n",
    "    break\n",
    "\n",
    "\n",
    "attr_ts, delta_ts = ig.attribute((flat_input, ts_sample), (flat_input, baseline_ts), target=0, return_convergence_delta=True)\n",
    "print(\"Time series attribution:\", attr_ts)\n",
    "print(\"Time series convergence delta:\", delta_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_ts = attr_ts[1].cpu().detach().numpy()  # 获取时间序列部分的归因\n",
    "ts_sample = ts_sample.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.mean(attr_ts, axis=0))\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Attribution')\n",
    "plt.title('Time Series Feature Importance using Integrated Gradients')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eicu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
