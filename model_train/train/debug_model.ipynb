{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append('/home/mei/nas/docker/thesis')\n",
    "from dataloader.ts_reader import MultiModalDataset, collate_fn\n",
    "from dataloader.pyg_reader import GraphDataset\n",
    "\n",
    "from lstm_gnn_embedding import PatientOutcomeModelEmbedding\n",
    "import pickle\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"/home/mei/nas/docker/thesis/data/hdf/train\"\n",
    "val_data_dir = \"/home/mei/nas/docker/thesis/data/hdf/val\"\n",
    "test_data_dir = \"/home/mei/nas/docker/thesis/data/hdf/test\"\n",
    "\n",
    "config = {  \n",
    "    \"data_dir\": \"/home/mei/nas/docker/thesis/data/hdf\",\n",
    "    \"graph_dir\": \"/home/mei/nas/docker/thesis/data/graphs\",\n",
    "    \"mode\": \"k_closest\",\n",
    "    \"k\": 3         \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading precomputed graph from /home/mei/nas/docker/thesis/data/graphs/diagnosis_graph_k_closest_k3.pt\n",
      "==> Loading flat features from /home/mei/nas/docker/thesis/data/hdf/final_flat.h5\n"
     ]
    }
   ],
   "source": [
    "# === LSTM + Flat Dataset ===\n",
    "lstm_dataset_train = MultiModalDataset(train_data_dir)\n",
    "lstm_dataset_val = MultiModalDataset(val_data_dir)\n",
    "lstm_dataset_test = MultiModalDataset(test_data_dir)\n",
    "\n",
    "lstm_loader_train = DataLoader(lstm_dataset_train , batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "lstm_loader_val = DataLoader(lstm_dataset_val , batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "lstm_loader_test = DataLoader(lstm_dataset_test , batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# === Graph Dataset ===\n",
    "\n",
    "graph_dataset = GraphDataset(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_patient_data(dataset, patient_id_debug):\n",
    "    idx_debug = None\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset.patient_ids[i] == patient_id_debug:\n",
    "            idx_debug = i\n",
    "            break\n",
    "    if idx_debug is None:\n",
    "        print(f\"Patient {patient_id_debug} not found in dataset.\")\n",
    "        return\n",
    "\n",
    "    pid, ts_data, flat_data, risk_data = dataset[idx_debug]\n",
    "    print(f\"Raw data for patient {patient_id_debug}:\")\n",
    "    print(f\"  ts_data shape: {ts_data.shape}\")\n",
    "    print(f\"  flat_data shape: {flat_data.shape}\")\n",
    "    print(f\"  risk_data shape: {risk_data.shape}\")\n",
    "    \n",
    "    return pid, ts_data, flat_data, risk_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data for patient 1788546:\n",
      "  ts_data shape: torch.Size([422, 162])\n",
      "  flat_data shape: torch.Size([104])\n",
      "  risk_data shape: torch.Size([422])\n"
     ]
    }
   ],
   "source": [
    "patient_id_debug = '1788546'\n",
    "pid, ts_data, flat_data, risk_data = debug_patient_data(lstm_dataset_train, patient_id_debug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data for patient 3132351:\n",
      "  ts_data shape: torch.Size([1759, 162])\n",
      "  flat_data shape: torch.Size([104])\n",
      "  risk_data shape: torch.Size([1759])\n"
     ]
    }
   ],
   "source": [
    "patient_id_debug = '3132351'\n",
    "pid2, ts_data2, flat_data2, risk_data2 = debug_patient_data(lstm_dataset_train, patient_id_debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After collate_fn:\n",
      "  debug_patient_ids: ['3132351', '1788546']\n",
      "  debug_padded_ts shape: torch.Size([2, 1759, 162])\n",
      "  debug_flat shape: torch.Size([2, 104])\n",
      "  debug_padded_risk shape: torch.Size([2, 1759])\n",
      "  debug_lengths: tensor([1759,  422])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "debug_batch = [(pid, ts_data, flat_data, risk_data),(pid2,ts_data2,flat_data2,risk_data2)]  # 只包含一个患者\n",
    "\n",
    "debug_patient_ids, debug_padded_ts, debug_flat, debug_padded_risk, debug_lengths = collate_fn(debug_batch)\n",
    "\n",
    "print(\"After collate_fn:\")\n",
    "print(f\"  debug_patient_ids: {debug_patient_ids}\")\n",
    "print(f\"  debug_padded_ts shape: {debug_padded_ts.shape}\")\n",
    "print(f\"  debug_flat shape: {debug_flat.shape}\")\n",
    "print(f\"  debug_padded_risk shape: {debug_padded_risk.shape}\")\n",
    "print(f\"  debug_lengths: {debug_lengths}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_input_dim = 104\n",
    "graph_input_dim = 104\n",
    "ts_input_dim = 162\n",
    "hidden_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   \n",
    "model = PatientOutcomeModelEmbedding(flat_input_dim, graph_input_dim, ts_input_dim, hidden_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph encoder output: node_embeddings.shape = torch.Size([11698, 128])\n",
      "batch graph embeddings shape = torch.Size([2, 128])\n",
      "flat encoder output: flat_emb.shape = torch.Size([2, 128])\n",
      "Time series Encoder input: x.shape = torch.Size([2, 1759, 162]), lengths.shape = torch.Size([2])\n",
      "packed sequence batch_sizes = tensor([2, 2, 2,  ..., 1, 1, 1])\n",
      "Time series Encoder output: out.shape = torch.Size([2, 1759, 256])\n",
      "Time series encoder output: ts_emb.shape = torch.Size([2, 1759, 256])\n",
      "risk predictor output: risk_scores.shape = torch.Size([2, 1759])\n",
      "combimed_embeddings.shape = torch.Size([2, 1759, 128])\n",
      "Model forward output:\n",
      "Model output shapes for debug patient:\n",
      "  risk_scores: torch.Size([2, 1759])\n",
      "  embeddings: torch.Size([2, 1759, 128])\n"
     ]
    }
   ],
   "source": [
    "train_loss = 0.0\n",
    "debug_patient_ids_tensor = torch.tensor([int(pid) for pid in debug_patient_ids], dtype=torch.long)\n",
    "\n",
    "debug_padded_ts = debug_padded_ts.to(device)\n",
    "debug_flat = debug_flat.to(device)\n",
    "debug_padded_risk = debug_padded_risk.to(device)\n",
    "debug_lengths = debug_lengths.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs, embedding = model(\n",
    "        debug_flat,\n",
    "        graph_dataset.graph_data,  # 包含 x, edge_index, patient_ids\n",
    "        debug_patient_ids_tensor,\n",
    "        debug_padded_ts,\n",
    "        debug_lengths\n",
    "        \n",
    "    )\n",
    "\n",
    "print(\"Model forward output:\")\n",
    "print(\"Model output shapes for debug patient:\")\n",
    "print(\"  risk_scores:\", outputs.shape)\n",
    "print(\"  embeddings:\", embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for patient 3132351: 0.04646523669362068\n",
      "valid_output shape: (1759,)\n",
      "valid_target shape: (1759,)\n",
      "Loss for patient 1788546: 0.03306068480014801\n",
      "valid_output shape: (422,)\n",
      "valid_target shape: (422,)\n",
      "Loss for debug patient: 0.0397629588842392\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "batch_size = outputs.shape[0]\n",
    "outputs_np = outputs.detach().cpu().numpy()\n",
    "padded_risk_np = debug_padded_risk.detach().cpu().numpy()\n",
    "lengths_np = debug_lengths.detach().cpu().numpy()\n",
    "\n",
    "for i in range(batch_size):\n",
    "    L = int(lengths_np[i])\n",
    "    valid_output = outputs_np[i][:L]\n",
    "    valid_target = padded_risk_np[i][:L]\n",
    "    sample_loss = criterion(torch.tensor(valid_output), torch.tensor(valid_target))\n",
    "    loss_list.append(sample_loss)\n",
    "    print(f\"Loss for patient {debug_patient_ids[i]}:\", sample_loss.item())\n",
    "    print(f\"valid_output shape: {valid_output.shape}\")\n",
    "    print(f\"valid_target shape: {valid_target.shape}\")\n",
    "\n",
    "loss = sum(loss_list) / len(loss_list)\n",
    "print(\"Loss for debug patient:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for patient 3132351: 0.04646524414420128\n",
      "valid_output shape: torch.Size([1759])\n",
      "valid_target shape: torch.Size([1759])\n",
      "Loss for patient 1788546: 0.03306068480014801\n",
      "valid_output shape: torch.Size([422])\n",
      "valid_target shape: torch.Size([422])\n",
      "Loss for debug patient: 0.039762966334819794\n"
     ]
    }
   ],
   "source": [
    "ts_mask = debug_padded_ts != -99\n",
    "ts_mask = ts_mask.any(dim=2)\n",
    "risk_mask =debug_padded_risk!= -99\n",
    "combined_mask = ts_mask & risk_mask\n",
    "masked_outputs = outputs[combined_mask]\n",
    "masked_risk_data = debug_padded_risk[combined_mask]\n",
    "loss_list = []\n",
    "batch_size = outputs.size(0)\n",
    "\n",
    "for i in range(batch_size):\n",
    "    valid_time_steps = combined_mask[i]  # boolean mask, marks which time steps are valid\n",
    "    valid_output = outputs[i][valid_time_steps]  # only take the valid time steps\n",
    "    valid_target = debug_padded_risk[i][valid_time_steps]\n",
    "    sample_loss = criterion(valid_output, valid_target)\n",
    "    loss_list.append(sample_loss)\n",
    "    print(f\"Loss for patient {debug_patient_ids[i]}: {sample_loss.item()}\")\n",
    "    print(f\"valid_output shape: {valid_output.shape}\")\n",
    "    print(f\"valid_target shape: {valid_target.shape}\")\n",
    "\n",
    "loss = torch.mean(torch.stack(loss_list))\n",
    "print(\"Loss for debug patient:\", loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eicu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
