{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/mei/nas/docker/thesis/model_train')\n",
    "from dataloader.ts_reader import MultiModalDataset, collate_fn_pre_train\n",
    "from model.autoencoder_ts import TimeSeriesAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"/home/mei/nas/docker/thesis/data/hdf/train\"\n",
    "val_data_dir = \"/home/mei/nas/docker/thesis/data/hdf/val\"\n",
    "test_data_dir = \"/home/mei/nas/docker/thesis/data/hdf/test\"\n",
    "\n",
    "lstm_dataset_train = MultiModalDataset(train_data_dir)\n",
    "lstm_dataset_val = MultiModalDataset(val_data_dir)\n",
    "lstm_dataset_test = MultiModalDataset(test_data_dir)\n",
    "\n",
    "lstm_loader_train = DataLoader(lstm_dataset_train, batch_size=32, shuffle=True, collate_fn=collate_fn_pre_train)\n",
    "lstm_loader_val = DataLoader(lstm_dataset_val, batch_size=32, shuffle=False,collate_fn=collate_fn_pre_train)\n",
    "lstm_loader_test = DataLoader(lstm_dataset_test, batch_size=32, shuffle=False,collate_fn=collate_fn_pre_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {\n",
    "    \"input_dim\": 324,\n",
    "    \"hidden_dim\": 32,\n",
    "    \"lr\": 0.0001,\n",
    "    \"epochs\": 10,\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TimeSeriesAutoencoder(\n",
    "    input_dim=best_config[\"input_dim\"],\n",
    "    hidden_dim=best_config[\"hidden_dim\"],\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_config[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, config, device):\n",
    "    best_val_loss = float(\"inf\")\n",
    "    model_dir = \"/home/mei/nas/docker/thesis/data/model/pre_train_autoencoder\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    best_model_path = os.path.join(model_dir, \"best_model_32_1e-4.pth\")\n",
    "\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            inputs, lengths = batch\n",
    "            inputs = inputs.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs, lengths)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs, lengths = batch\n",
    "                inputs = inputs.to(device)\n",
    "                lengths = lengths.to(device)\n",
    "\n",
    "                outputs, _ = model(inputs, lengths)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{config['epochs']}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Best model saved at {best_model_path} with Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    print(f\"Training complete. Best Validation Loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.1295, Val Loss: 0.0775\n",
      "Best model saved at /home/mei/nas/docker/thesis/data/model/pre_train_autoencoder/best_model_32_1e-4.pth with Val Loss: 0.0775\n",
      "Epoch 2/10, Train Loss: 0.0553, Val Loss: 0.0444\n",
      "Best model saved at /home/mei/nas/docker/thesis/data/model/pre_train_autoencoder/best_model_32_1e-4.pth with Val Loss: 0.0444\n",
      "Epoch 3/10, Train Loss: 0.0397, Val Loss: 0.0355\n",
      "Best model saved at /home/mei/nas/docker/thesis/data/model/pre_train_autoencoder/best_model_32_1e-4.pth with Val Loss: 0.0355\n",
      "Epoch 4/10, Train Loss: 0.0316, Val Loss: 0.0281\n",
      "Best model saved at /home/mei/nas/docker/thesis/data/model/pre_train_autoencoder/best_model_32_1e-4.pth with Val Loss: 0.0281\n",
      "Epoch 5/10, Train Loss: 0.0249, Val Loss: 0.0222\n",
      "Best model saved at /home/mei/nas/docker/thesis/data/model/pre_train_autoencoder/best_model_32_1e-4.pth with Val Loss: 0.0222\n",
      "Epoch 6/10, Train Loss: 0.0196, Val Loss: 0.0177\n",
      "Best model saved at /home/mei/nas/docker/thesis/data/model/pre_train_autoencoder/best_model_32_1e-4.pth with Val Loss: 0.0177\n",
      "Epoch 7/10, Train Loss: 0.0162, Val Loss: 0.0152\n",
      "Best model saved at /home/mei/nas/docker/thesis/data/model/pre_train_autoencoder/best_model_32_1e-4.pth with Val Loss: 0.0152\n",
      "Epoch 8/10, Train Loss: 0.0144, Val Loss: 0.0142\n",
      "Best model saved at /home/mei/nas/docker/thesis/data/model/pre_train_autoencoder/best_model_32_1e-4.pth with Val Loss: 0.0142\n",
      "Epoch 9/10, Train Loss: 0.0139, Val Loss: 0.0140\n",
      "Best model saved at /home/mei/nas/docker/thesis/data/model/pre_train_autoencoder/best_model_32_1e-4.pth with Val Loss: 0.0140\n",
      "Epoch 10/10, Train Loss: 0.0138, Val Loss: 0.0140\n",
      "Training complete. Best Validation Loss: 0.0140\n"
     ]
    }
   ],
   "source": [
    "train_model(model, lstm_loader_train, lstm_loader_val, criterion, optimizer, best_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    mae_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs, lengths = batch\n",
    "            inputs = inputs.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            outputs, _ = model(inputs, lengths)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            mae = torch.abs(outputs - inputs).mean(dim=(1, 2))\n",
    "            mae_list.extend(mae.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstruction(model, test_loader, device, num_samples=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "\n",
    "            inputs, lengths = batch\n",
    "            inputs = inputs.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            outputs, _ = model(inputs, lengths)\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(inputs[0].cpu().numpy(), label=\"Original\")\n",
    "            plt.plot(outputs[0].cpu().numpy(), label=\"Reconstructed\")\n",
    "            plt.legend()\n",
    "            plt.title(f\"Sample {i+1}: Original vs Reconstructed\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"/home/mei/nas/docker/thesis/data/model/pre_train_autoencoder/best_model_32_1e-4.pth\"\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "test_model(model, lstm_loader_test, criterion, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eicu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
